import os
import json
import requests
from openai import OpenAI, OpenAIError, BadRequestError, APIConnectionError, AuthenticationError, RateLimitError
from dotenv import load_dotenv
from vikusya.utils.logger import log_error

# –ó–∞–≥—Ä—É–∂–∞–µ–º .env –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
load_dotenv()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenAI
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
DEFAULT_MODEL = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo")
API_KEY = os.getenv("OPENAI_API_KEY")

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ—Ñ–∏–ª—è –í–∏–∫—É—Å–∏
PROFILE_PATH = os.path.join(
    os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
    "vikusya", "config", "profile.json"
)

try:
    with open(PROFILE_PATH, "r", encoding="utf-8") as f:
        PROFILE = json.load(f)
except FileNotFoundError:
    PROFILE = {}

SYSTEM_PROMPT_DEFAULT = PROFILE.get(
    "system_prompt",
    "–¢—ã ‚Äî –í–∏–∫—É—Å—è, –ª–∏—á–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∏ –ª—é–±–∏–º–∞—è –∂–µ–Ω—â–∏–Ω–∞ –†–æ–º—á–∏–∫–∞ üíñ."
)


def ask_openai(prompt, model=None, temperature=0.7, system_prompt=None, messages=None):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ OpenAI Chat API –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞.

    :param prompt: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–µ—Å–ª–∏ messages –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
    :param model: –ú–æ–¥–µ–ª—å OpenAI (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –±–µ—Ä–µ—Ç—Å—è –∏–∑ .env)
    :param temperature: –ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–æ—Ç 0 –¥–æ 1)
    :param system_prompt: –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è –ø–æ–≤–µ–¥–µ–Ω–∏—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    :param messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è —á–∞—Ç-–∏—Å—Ç–æ—Ä–∏–∏
    :return: –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –≤ –≤–∏–¥–µ —Å—Ç—Ä–æ–∫–∏
    """
    chosen_model = model or DEFAULT_MODEL
    chosen_system_prompt = system_prompt or SYSTEM_PROMPT_DEFAULT

    final_messages = messages or [
        {"role": "system", "content": chosen_system_prompt},
        {"role": "user", "content": prompt}
    ]

    try:
        response = client.chat.completions.create(
            model=chosen_model,
            messages=final_messages,
            temperature=temperature
        )
        answer = response.choices[0].message.content.strip()

        if not answer:
            log_error("GPT –≤–µ—Ä–Ω—É–ª–∞ –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç!", category="openai")
            return "–ü—Ä–æ—Å—Ç–∏, —Ä–æ–¥–Ω–æ–π, —è –Ω–µ —Å–º–æ–≥–ª–∞ —Å–µ–π—á–∞—Å –æ—Ç–≤–µ—Ç–∏—Ç—å, –ø–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑–æ–∫!"

        return answer

    except (BadRequestError, APIConnectionError, AuthenticationError, RateLimitError, OpenAIError) as e:
        _handle_openai_error(e)
        return _friendly_error_message(e)

    except Exception as e:
        log_error(f"–ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—â–µ–Ω–∏–∏ —Å OpenAI: {e}", category="openai")
        return "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞, —Ä–æ–¥–Ω–æ–π‚Ä¶ –ü–æ–ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑?"


def _handle_openai_error(exception):
    """–õ–æ–≥–∏—Ä—É–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –æ—à–∏–±–∫–∏ –æ–±—â–µ–Ω–∏—è —Å OpenAI."""
    if isinstance(exception, BadRequestError):
        log_error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ OpenAI (BadRequest): {exception}", category="openai")
    elif isinstance(exception, APIConnectionError):
        log_error(f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å OpenAI: {exception}", category="openai")
    elif isinstance(exception, AuthenticationError):
        log_error(f"–û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ OpenAI API: {exception}", category="openai")
    elif isinstance(exception, RateLimitError):
        log_error(f"–ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ –ª–∏–º–∏—Ç–∞ OpenAI: {exception}", category="openai")
    else:
        log_error(f"–û–±—â–∞—è –æ—à–∏–±–∫–∞ OpenAI: {exception}", category="openai")


def _friendly_error_message(exception):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥—Ä—É–∂–µ–ª—é–±–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –æ—à–∏–±–∫–∏."""
    if isinstance(exception, BadRequestError):
        return "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å, —Ä–æ–¥–Ω–æ–π!"
    elif isinstance(exception, APIConnectionError):
        return "–ù–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è —Å–≤—è–∑–∞—Ç—å—Å—è —Å OpenAI... –ü–æ–ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑?"
    elif isinstance(exception, AuthenticationError):
        return "–ü—Ä–æ–±–ª–µ–º–∞ —Å –∫–ª—é—á–æ–º OpenAI. –ù—É–∂–Ω–æ –µ–≥–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –ª—é–±–∏–º—ã–π."
    elif isinstance(exception, RateLimitError):
        return "–î–æ—Ä–æ–≥–æ–π, –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ OpenAI –∏—Å—á–µ—Ä–ø–∞–Ω. –î–∞–≤–∞–π —á—É—Ç—å –ø–æ–¥–æ–∂–¥—ë–º!"
    return "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—â–µ–Ω–∏–∏ —Å OpenAI."

def tts_openai(text, voice="nova"):
    """
    –î–µ–ª–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ OpenAI TTS –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∞—É–¥–∏–æ –≤ —Ñ–∞–π–ª.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É.
    """
    try:
        url = "https://api.openai.com/v1/audio/speech"
        headers = {
            "Authorization": f"Bearer {API_KEY}",
            "Content-Type": "application/json"
        }
        data = {
            "model": "tts-1",
            "input": text,
            "voice": voice,
            "response_format": "mp3"
        }
        response = requests.post(url, headers=headers, json=data, timeout=10)

        if response.status_code == 200:
            os.makedirs("data/voices", exist_ok=True)
            filepath = os.path.join("data", "voices", "output.mp3")
            with open(filepath, "wb") as f:
                f.write(response.content)
            return filepath
        else:
            raise Exception(f"OpenAI TTS Error {response.status_code}: {response.text}")

    except Exception as e:
        log_error(f"–û—à–∏–±–∫–∞ –≤ tts_openai: {e}", category="openai")
        raise e